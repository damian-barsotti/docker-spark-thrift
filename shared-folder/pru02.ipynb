{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac6fb60-65a3-4e56-b859-e8a09122c04e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "warehouse_location = \"/shared-folder/spark-warehouse\"\n",
    "url = \"jdbc:mysql://metastore-db/metastore\"\n",
    "driver = \"com.mysql.cj.jdbc.Driver\"\n",
    "username = \"root\"\n",
    "password = \"my-secret-pw\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"javax.jdo.option.ConnectionURL\", url) \\\n",
    "    .config(\"javax.jdo.option.ConnectionDriverName\", driver) \\\n",
    "    .config(\"javax.jdo.option.ConnectionUserName\", username) \\\n",
    "    .config(\"javax.jdo.option.ConnectionPassword\", password) \\\n",
    "    .appName(\"API Spark\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd9e6ed-ccb1-4313-892d-e824618ceb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"/shared-folder/load_data_write_to_server.py\"\n",
    "\n",
    "lines = sc.textFile(file_name)\n",
    "\n",
    "words = lines \\\n",
    "    .flatMap(lambda line: line.split(\" \")) \\\n",
    "    .filter(lambda word: word)\n",
    "\n",
    "#MapReduce\n",
    "wordCount = words \\\n",
    "    .map(lambda word: (word,1)) \\\n",
    "    .reduceByKey(lambda n,m: n+m)\n",
    "\n",
    "result = wordCount \\\n",
    "    .sortBy((lambda p: p[1]), ascending = False) # ordena por cantidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906dc268-fdc3-4e60-828c-80d211e482f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 5\n",
      "import 4\n",
      "from 3\n",
      "\\ 3\n",
      "# 3\n",
      "spark 2\n",
      "pyspark.sql 2\n",
      "#os.exit() 1\n",
      "Leer 1\n",
      "delimiter=DELIMITER, 1\n"
     ]
    }
   ],
   "source": [
    "local_result = result.collect() # Traigo desde cluster\n",
    "\n",
    "for word, count in local_result[:10]: # tomo 10\n",
    "    print(word, count) # los imprimo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a33b38-2f00-4aea-b8d2-0267ad6c7926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b294167-3488-40b7-b9e2-11a1426bd873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
